{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn import svm\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_file = './data/stock_comments_seg.csv'\n",
    "data_path = './data'\n",
    "pos_corpus = 'positive.txt'\n",
    "neg_corpus = 'negative.txt'\n",
    "\n",
    "# Concact positive and negative corpus together, and return with corresponding tokens\n",
    "def load_dataset_tokenized():\n",
    "    pos_file = os.path.join(data_path, pos_corpus)\n",
    "    neg_file = os.path.join(data_path, neg_corpus)\n",
    "\n",
    "    pos_sents = []\n",
    "    with open(pos_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            tokens = line.split(' ')\n",
    "            sent = []\n",
    "            for t in tokens:\n",
    "                if t.strip():\n",
    "                    sent.append(t.strip())\n",
    "            pos_sents.append(sent)\n",
    "\n",
    "    neg_sents = []\n",
    "    with open(neg_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            tokens = line.split(' ')\n",
    "            sent = []\n",
    "            for t in tokens:\n",
    "                if t.strip():\n",
    "                    sent.append(t.strip())\n",
    "            neg_sents.append(sent)\n",
    "            \n",
    "    # Ensure same number of pos and neg reviews \n",
    "    balance_len = min(len(pos_sents), len(neg_sents))\n",
    "\n",
    "    texts = pos_sents + neg_sents\n",
    "    labels = [1] * balance_len + [0] * balance_len\n",
    "\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalauting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "        return doc\n",
    "    \n",
    "def KFold_validation(clf, X, y):\n",
    "    \n",
    "    # initialize output\n",
    "    acc = []\n",
    "    pos_precision, pos_recall, pos_f1_score = [], [], []\n",
    "    neg_precision, neg_recall, neg_f1_score = [], [], []\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for train, test in kf.split(X):\n",
    "        X_train = [X[i] for i in train]\n",
    "        X_test = [X[i] for i in test]\n",
    "        y_train = [y[i] for i in train]\n",
    "        y_test = [y[i] for i in test]\n",
    "\n",
    "        vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                                     tokenizer=dummy_fun,\n",
    "                                     preprocessor=dummy_fun,\n",
    "                                     token_pattern=None)\n",
    "\n",
    "        vectorizer.fit(X_train)\n",
    "        # vectorize train and test sets\n",
    "        X_train = vectorizer.transform(X_train)\n",
    "        X_test = vectorizer.transform(X_test)\n",
    "        # training the model\n",
    "        clf.fit(X_train, y_train)\n",
    "        # get prediction\n",
    "        preds = clf.predict(X_test)\n",
    "\n",
    "        acc.append(metrics.accuracy_score(y_test, preds))\n",
    "        pos_precision.append(metrics.precision_score(y_test, preds, pos_label=1))\n",
    "        pos_recall.append(metrics.recall_score(y_test, preds, pos_label=1))\n",
    "        pos_f1_score.append(metrics.f1_score(y_test, preds, pos_label=1))\n",
    "        neg_precision.append(metrics.precision_score(y_test, preds, pos_label=0))\n",
    "        neg_recall.append(metrics.recall_score(y_test, preds, pos_label=0))\n",
    "        neg_f1_score.append(metrics.f1_score(y_test, preds, pos_label=0))\n",
    "\n",
    "    return (np.mean(acc), np.mean(pos_precision), np.mean(pos_recall), np.mean(pos_f1_score),\n",
    "            np.mean(neg_precision), np.mean(neg_recall), np.mean(neg_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate different models, return a DataFrame containing the performance metrics\n",
    "def evaluate_models():\n",
    "\n",
    "    X, y = load_dataset_tokenized()\n",
    "\n",
    "    cols = ['metrics', 'accuracy',  'pos_precision', 'pos_recall', 'pos_f1_score', 'neg_precision', 'neg_recall', 'neg_f1_score']\n",
    "    scores = []\n",
    "\n",
    "    classifiers = [\n",
    "        ('LinearSVC', svm.LinearSVC()),\n",
    "        ('LogisticReg', LogisticRegression()),\n",
    "        ('SGD', SGDClassifier()),\n",
    "        ('MultinomialNB', naive_bayes.MultinomialNB()),\n",
    "        ('KNN', KNeighborsClassifier()),\n",
    "        ('DecisionTree', DecisionTreeClassifier()),\n",
    "        ('RandomForest', RandomForestClassifier()),\n",
    "        ('AdaBoost', AdaBoostClassifier(base_estimator=LogisticRegression()))]\n",
    "\n",
    "    for name, clf in classifiers:\n",
    "        score = KFold_validation(clf, X, y)\n",
    "        row = [name]\n",
    "        row.extend(score)\n",
    "        scores.append(row)\n",
    "\n",
    "    df = pd.DataFrame(scores, columns=cols).T\n",
    "    df.columns = df.iloc[0]\n",
    "    df.drop(df.index[[0]], inplace=True)\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metrics</th>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>LogisticReg</th>\n",
       "      <th>SGD</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>AdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.881593</td>\n",
       "      <td>0.880834</td>\n",
       "      <td>0.882895</td>\n",
       "      <td>0.879640</td>\n",
       "      <td>0.820924</td>\n",
       "      <td>0.794227</td>\n",
       "      <td>0.843500</td>\n",
       "      <td>0.771659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_precision</th>\n",
       "      <td>0.880544</td>\n",
       "      <td>0.879024</td>\n",
       "      <td>0.884003</td>\n",
       "      <td>0.882137</td>\n",
       "      <td>0.808250</td>\n",
       "      <td>0.810372</td>\n",
       "      <td>0.866348</td>\n",
       "      <td>0.797129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_recall</th>\n",
       "      <td>0.882481</td>\n",
       "      <td>0.882941</td>\n",
       "      <td>0.880842</td>\n",
       "      <td>0.876015</td>\n",
       "      <td>0.840896</td>\n",
       "      <td>0.767061</td>\n",
       "      <td>0.812089</td>\n",
       "      <td>0.798650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_f1_score</th>\n",
       "      <td>0.881483</td>\n",
       "      <td>0.880898</td>\n",
       "      <td>0.882393</td>\n",
       "      <td>0.879043</td>\n",
       "      <td>0.824202</td>\n",
       "      <td>0.788035</td>\n",
       "      <td>0.838269</td>\n",
       "      <td>0.765202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_precision</th>\n",
       "      <td>0.882443</td>\n",
       "      <td>0.882578</td>\n",
       "      <td>0.881674</td>\n",
       "      <td>0.876666</td>\n",
       "      <td>0.834168</td>\n",
       "      <td>0.779216</td>\n",
       "      <td>0.822977</td>\n",
       "      <td>0.825027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_recall</th>\n",
       "      <td>0.880121</td>\n",
       "      <td>0.878210</td>\n",
       "      <td>0.884220</td>\n",
       "      <td>0.883188</td>\n",
       "      <td>0.800378</td>\n",
       "      <td>0.821041</td>\n",
       "      <td>0.874529</td>\n",
       "      <td>0.759168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neg_f1_score</th>\n",
       "      <td>0.881251</td>\n",
       "      <td>0.880306</td>\n",
       "      <td>0.882916</td>\n",
       "      <td>0.879890</td>\n",
       "      <td>0.816867</td>\n",
       "      <td>0.799500</td>\n",
       "      <td>0.847906</td>\n",
       "      <td>0.766304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metrics        LinearSVC  LogisticReg       SGD  MultinomialNB       KNN  \\\n",
       "accuracy        0.881593     0.880834  0.882895       0.879640  0.820924   \n",
       "pos_precision   0.880544     0.879024  0.884003       0.882137  0.808250   \n",
       "pos_recall      0.882481     0.882941  0.880842       0.876015  0.840896   \n",
       "pos_f1_score    0.881483     0.880898  0.882393       0.879043  0.824202   \n",
       "neg_precision   0.882443     0.882578  0.881674       0.876666  0.834168   \n",
       "neg_recall      0.880121     0.878210  0.884220       0.883188  0.800378   \n",
       "neg_f1_score    0.881251     0.880306  0.882916       0.879890  0.816867   \n",
       "\n",
       "metrics        DecisionTree  RandomForest  AdaBoost  \n",
       "accuracy           0.794227      0.843500  0.771659  \n",
       "pos_precision      0.810372      0.866348  0.797129  \n",
       "pos_recall         0.767061      0.812089  0.798650  \n",
       "pos_f1_score       0.788035      0.838269  0.765202  \n",
       "neg_precision      0.779216      0.822977  0.825027  \n",
       "neg_recall         0.821041      0.874529  0.759168  \n",
       "neg_f1_score       0.799500      0.847906  0.766304  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get model performances\n",
    "evaluate_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Bagging Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep frist 7 models with best performances\n",
    "# save the prediction in another file\n",
    "def predict_with_bagging():\n",
    "\n",
    "    # Loading training data\n",
    "    X, y = load_dataset_tokenized()\n",
    "    vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                                 tokenizer=dummy_fun,\n",
    "                                 preprocessor=dummy_fun,\n",
    "                                 token_pattern=None)\n",
    "\n",
    "    X = vectorizer.fit_transform(X)\n",
    "\n",
    "    # Loading review file\n",
    "    df = pd.read_csv(comment_file)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    # Reformat the data\n",
    "    df['created_time'] = pd.to_datetime(df['created_time'], format='%Y-%m-%d %H:%M:%S')\n",
    "    # Split the word in each review\n",
    "    df['title'].apply(lambda x: [w.strip() for w in x.split()])\n",
    "\n",
    "    texts = df['title']\n",
    "    texts = vectorizer.transform(texts)\n",
    "\n",
    "    # initialize the output\n",
    "    df['preds'] = 0\n",
    "\n",
    "    classifiers = [\n",
    "    ('LinearSVC', svm.LinearSVC()),\n",
    "    ('LogisticReg', LogisticRegression()),\n",
    "    ('SGD', SGDClassifier()),\n",
    "    ('MultinomialNB', naive_bayes.MultinomialNB()),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('DecisionTree', DecisionTreeClassifier()),\n",
    "    ('RandomForest', RandomForestClassifier())]\n",
    "    \n",
    "    for name, clf in classifiers:\n",
    "        clf.fit(X, y)\n",
    "        pred = clf.predict(texts)\n",
    "        df[name] = pred\n",
    "        df['preds'] = df['preds'] + df[name]\n",
    "    df['preds'] = df['preds'].apply(lambda x: 0 if x < 4 else 1)\n",
    "    \n",
    "    # generate the predcition\n",
    "    df.to_csv('generated_data/stock_comments_predicted.csv', index=False)\n",
    "    print(\"Prediction has saved to file\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction has saved to file\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_with_bagging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute BI-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bi(row):\n",
    "    \n",
    "    pos = row[row == 1].count()\n",
    "    neg = row[row == 0].count()\n",
    "    bi = np.log((1 + pos) / (1 + neg))\n",
    "\n",
    "    return bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group reviews by date\n",
    "grouped = prediction['preds'].groupby(prediction.created_time.dt.date)\n",
    "# Generate bi score of each day\n",
    "bi_index = grouped.apply(get_bi)\n",
    "bi_index = bi_index.rename(\"BI\")\n",
    "# Get trading date according to Shanghai Index file\n",
    "quotes = pd.read_csv('./data/sh000001.csv', parse_dates=['date'])\n",
    "quotes.set_index('date', inplace=True)\n",
    "# Merge sentiment \n",
    "bi_index.index = pd.to_datetime(bi_index.index)\n",
    "merged = pd.merge(bi_index, quotes, how='left', left_index=True, right_index=True)\n",
    "merged.fillna(method='ffill', inplace=True)\n",
    "# Save the bi index\n",
    "merged.to_csv('generated_data/bi_idx.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
