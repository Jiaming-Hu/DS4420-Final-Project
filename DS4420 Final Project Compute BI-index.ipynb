{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file at specific path\n",
    "# prepare the review data\n",
    "def get_reviews(path, file):\n",
    "    f = os.path.join(path, file)\n",
    "    reviews = []\n",
    "    with open(f, 'r', encoding = 'utf-8') as f:\n",
    "        for line in f:\n",
    "            words = line.split(' ')\n",
    "            sent = []\n",
    "            for word in words:\n",
    "                if word.strip():\n",
    "                    sent.append(word.strip())\n",
    "            reviews.append(sent)\n",
    "    return reviews\n",
    "\n",
    "# add labels to the reviews, prepare the traning data X (reviews), y (labels)\n",
    "def get_training_data():\n",
    "    # get positive reviews\n",
    "    pos_reviews = get_reviews('./data', 'positive.txt')\n",
    "    # get negative reviews\n",
    "    neg_reviews = get_reviews('./data', 'negative.txt')\n",
    "            \n",
    "    reviews = pos_reviews + neg_reviews\n",
    "    sents = [1] * len(pos_reviews) + [0] * len(neg_reviews)\n",
    "\n",
    "    return reviews, sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalauting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_return(f):\n",
    "    return f\n",
    "\n",
    "def KFold_validation(clf, X, y):\n",
    "    \n",
    "    # initialize output\n",
    "    acc, precision, recall, f1_score = [], [], [], []\n",
    "\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 30)\n",
    "    for train, test in kf.split(X):\n",
    "        X_train = [X[i] for i in train]\n",
    "        X_test = [X[i] for i in test]\n",
    "        y_train = [y[i] for i in train]\n",
    "        y_test = [y[i] for i in test]\n",
    "\n",
    "        # Use TF-IDF to vectorize the reviews\n",
    "        vectorizer = TfidfVectorizer(analyzer = 'word',\n",
    "                                     tokenizer = simple_return,\n",
    "                                     preprocessor = simple_return,\n",
    "                                     token_pattern =None)\n",
    "\n",
    "        vectorizer.fit(X_train)\n",
    "        # vectorize train and test sets\n",
    "        X_train = vectorizer.transform(X_train)\n",
    "        X_test = vectorizer.transform(X_test)\n",
    "        # training the model\n",
    "        clf.fit(X_train, y_train)\n",
    "        # get prediction\n",
    "        preds = clf.predict(X_test)\n",
    "        \n",
    "        # append to performance lists\n",
    "        acc.append(metrics.accuracy_score(y_test, preds))\n",
    "        precision.append(metrics.precision_score(y_test, preds, pos_label = 1))\n",
    "        recall.append(metrics.recall_score(y_test, preds, pos_label = 1))\n",
    "        f1_score.append(metrics.f1_score(y_test, preds, pos_label = 1))\n",
    "\n",
    "    # get averave of all the metrics\n",
    "    return (np.mean(acc), np.mean(precision), np.mean(recall), np.mean(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate different models, return a DataFrame containing the performance metrics\n",
    "def evaluate_models(clfs):\n",
    "\n",
    "    X, y = get_training_data()\n",
    "\n",
    "    cols = ['metrics', 'accuracy',  'precision', 'recall', 'f1_score']\n",
    "    scores = []\n",
    "\n",
    "    for name, clf in clfs:\n",
    "        score = KFold_validation(clf, X, y)\n",
    "        row = [name]\n",
    "        row.extend(score)\n",
    "        scores.append(row)\n",
    "\n",
    "    df = pd.DataFrame(scores, columns = cols).T\n",
    "    df.columns = df.iloc[0]\n",
    "    df.drop(df.index[[0]], inplace = True)\n",
    "    df = df.apply(pd.to_numeric, errors = 'ignore')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metrics</th>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>LogisticReg</th>\n",
       "      <th>SGD</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>AdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.883330</td>\n",
       "      <td>0.882462</td>\n",
       "      <td>0.883873</td>\n",
       "      <td>0.877469</td>\n",
       "      <td>0.817344</td>\n",
       "      <td>0.800196</td>\n",
       "      <td>0.845019</td>\n",
       "      <td>0.826463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.884507</td>\n",
       "      <td>0.881430</td>\n",
       "      <td>0.887066</td>\n",
       "      <td>0.883472</td>\n",
       "      <td>0.809008</td>\n",
       "      <td>0.818643</td>\n",
       "      <td>0.867357</td>\n",
       "      <td>0.827792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.882010</td>\n",
       "      <td>0.883984</td>\n",
       "      <td>0.879838</td>\n",
       "      <td>0.869941</td>\n",
       "      <td>0.831042</td>\n",
       "      <td>0.771230</td>\n",
       "      <td>0.814599</td>\n",
       "      <td>0.842726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.883209</td>\n",
       "      <td>0.882670</td>\n",
       "      <td>0.883400</td>\n",
       "      <td>0.876548</td>\n",
       "      <td>0.819673</td>\n",
       "      <td>0.794202</td>\n",
       "      <td>0.840140</td>\n",
       "      <td>0.828838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metrics    LinearSVC  LogisticReg       SGD  MultinomialNB       KNN  \\\n",
       "accuracy    0.883330     0.882462  0.883873       0.877469  0.817344   \n",
       "precision   0.884507     0.881430  0.887066       0.883472  0.809008   \n",
       "recall      0.882010     0.883984  0.879838       0.869941  0.831042   \n",
       "f1_score    0.883209     0.882670  0.883400       0.876548  0.819673   \n",
       "\n",
       "metrics    DecisionTree  RandomForest  AdaBoost  \n",
       "accuracy       0.800196      0.845019  0.826463  \n",
       "precision      0.818643      0.867357  0.827792  \n",
       "recall         0.771230      0.814599  0.842726  \n",
       "f1_score       0.794202      0.840140  0.828838  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get model performances\n",
    "classifiers = [('LinearSVC', svm.LinearSVC()),\n",
    "               ('LogisticReg', LogisticRegression()),\n",
    "               ('SGD', SGDClassifier()),\n",
    "               ('MultinomialNB', naive_bayes.MultinomialNB()),\n",
    "               ('KNN', KNeighborsClassifier()),\n",
    "               ('DecisionTree', DecisionTreeClassifier()),\n",
    "               ('RandomForest', RandomForestClassifier()),\n",
    "               ('AdaBoost', AdaBoostClassifier(base_estimator = LogisticRegression()))]\n",
    "\n",
    "evaluate_models(classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Bagging Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep frist 5 models with best performances\n",
    "# save the prediction in another file\n",
    "def predict_with_bagging(clfs):\n",
    "\n",
    "    # Loading training data\n",
    "    X, y = get_training_data()\n",
    "    \n",
    "    # Use TF-IDF to vectorize the reviews\n",
    "    vectorizer = TfidfVectorizer(analyzer = 'word',\n",
    "                                 tokenizer = simple_return,\n",
    "                                 preprocessor = simple_return,\n",
    "                                 token_pattern = None)\n",
    "\n",
    "    X = vectorizer.fit_transform(X)\n",
    "\n",
    "    # Loading review file\n",
    "    df = pd.read_csv('./data/stock_comments_seg.csv')\n",
    "    df.dropna(inplace = True)\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    # Reformat the data\n",
    "    df['created_time'] = pd.to_datetime(df['created_time'], format = '%Y-%m-%d %H:%M:%S')\n",
    "    # Split the word in each review\n",
    "    df['title'].apply(lambda x: [w.strip() for w in x.split()])\n",
    "\n",
    "    reviews = df['title']\n",
    "    reviews = vectorizer.transform(reviews)\n",
    "\n",
    "    # initialize the output\n",
    "    df['preds'] = 0\n",
    "\n",
    "    for name, clf in clfs:\n",
    "        clf.fit(X, y)\n",
    "        pred = clf.predict(reviews)\n",
    "        df[name] = pred\n",
    "        df['preds'] = df['preds'] + df[name]\n",
    "    df['preds'] = df['preds'].apply(lambda x: 0 if x < 3 else 1)\n",
    "    \n",
    "    # generate the predcition\n",
    "    df.to_csv('generated_data/stock_comments_predicted.csv', index = False)\n",
    "    print(\"Prediction has saved to file\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction has saved to file\n"
     ]
    }
   ],
   "source": [
    "classifiers = [('LinearSVC', svm.LinearSVC()),\n",
    "               ('LogisticReg', LogisticRegression()),\n",
    "               ('SGD', SGDClassifier()),\n",
    "               ('MultinomialNB', naive_bayes.MultinomialNB()),\n",
    "               ('RandomForest', RandomForestClassifier())]\n",
    "\n",
    "prediction = predict_with_bagging(classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute BI-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bi(row):\n",
    "    \n",
    "    pos = row[row == 1].count()\n",
    "    neg = row[row == 0].count()\n",
    "    bi = np.log((1 + pos) / (1 + neg))\n",
    "\n",
    "    return bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group reviews by date\n",
    "grouped = prediction['preds'].groupby(prediction.created_time.dt.date)\n",
    "# Generate bi score of each day\n",
    "bi_index = grouped.apply(get_bi)\n",
    "bi_index = bi_index.rename(\"BI\")\n",
    "# Get trading date according to Shanghai Index file\n",
    "quotes = pd.read_csv('./data/sh000001.csv', parse_dates = ['date'])\n",
    "quotes.set_index('date', inplace = True)\n",
    "# Merge sentiment \n",
    "bi_index.index = pd.to_datetime(bi_index.index)\n",
    "merged = pd.merge(bi_index, quotes, how = 'left', left_index = True, right_index = True)\n",
    "merged.fillna(method = 'ffill', inplace = True)\n",
    "# Save the bi index\n",
    "merged.to_csv('generated_data/bi_idx.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
