{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_file = './data/stock_comments_seg.csv'\n",
    "data_path = './data'\n",
    "pos_corpus = 'positive.txt'\n",
    "neg_corpus = 'negative.txt'\n",
    "\n",
    "# Concact positive and negative corpus together, and return with corresponding tokens\n",
    "def load_dataset_tokenized():\n",
    "    pos_file = os.path.join(data_path, pos_corpus)\n",
    "    neg_file = os.path.join(data_path, neg_corpus)\n",
    "\n",
    "    pos_sents = []\n",
    "    with open(pos_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            tokens = line.split(' ')\n",
    "            sent = []\n",
    "            for t in tokens:\n",
    "                if t.strip():\n",
    "                    sent.append(t.strip())\n",
    "            pos_sents.append(sent)\n",
    "\n",
    "    neg_sents = []\n",
    "    with open(neg_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            tokens = line.split(' ')\n",
    "            sent = []\n",
    "            for t in tokens:\n",
    "                if t.strip():\n",
    "                    sent.append(t.strip())\n",
    "            neg_sents.append(sent)\n",
    "            \n",
    "    # Ensure same number of pos and neg reviews \n",
    "    balance_len = min(len(pos_sents), len(neg_sents))\n",
    "\n",
    "    texts = pos_sents + neg_sents\n",
    "    labels = [1] * balance_len + [0] * balance_len\n",
    "\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalauting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_return(f):\n",
    "    return f\n",
    "\n",
    "def KFold_validation(clf, X, y):\n",
    "    \n",
    "    # initialize output\n",
    "    acc = []\n",
    "    precision, recall, f1_score = [], [], []\n",
    "\n",
    "    kf = KFold(n_splits = 5, shuffle = True, random_state = 30)\n",
    "    for train, test in kf.split(X):\n",
    "        X_train = [X[i] for i in train]\n",
    "        X_test = [X[i] for i in test]\n",
    "        y_train = [y[i] for i in train]\n",
    "        y_test = [y[i] for i in test]\n",
    "\n",
    "        vectorizer = TfidfVectorizer(analyzer = 'word',\n",
    "                                     tokenizer = simple_return,\n",
    "                                     preprocessor = simple_return,\n",
    "                                     token_pattern =None)\n",
    "\n",
    "        vectorizer.fit(X_train)\n",
    "        # vectorize train and test sets\n",
    "        X_train = vectorizer.transform(X_train)\n",
    "        X_test = vectorizer.transform(X_test)\n",
    "        # training the model\n",
    "        clf.fit(X_train, y_train)\n",
    "        # get prediction\n",
    "        preds = clf.predict(X_test)\n",
    "\n",
    "        acc.append(metrics.accuracy_score(y_test, preds))\n",
    "        precision.append(metrics.precision_score(y_test, preds, pos_label = 1))\n",
    "        recall.append(metrics.recall_score(y_test, preds, pos_label = 1))\n",
    "        f1_score.append(metrics.f1_score(y_test, preds, pos_label = 1))\n",
    "\n",
    "    return (np.mean(acc), np.mean(precision), np.mean(recall), np.mean(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate different models, return a DataFrame containing the performance metrics\n",
    "def evaluate_models():\n",
    "\n",
    "    X, y = load_dataset_tokenized()\n",
    "\n",
    "    cols = ['metrics', 'accuracy',  'precision', 'recall', 'f1_score']\n",
    "    scores = []\n",
    "\n",
    "    classifiers = [\n",
    "        ('LinearSVC', svm.LinearSVC()),\n",
    "        ('LogisticReg', LogisticRegression()),\n",
    "        ('SGD', SGDClassifier()),\n",
    "        ('MultinomialNB', naive_bayes.MultinomialNB()),\n",
    "        ('KNN', KNeighborsClassifier()),\n",
    "        ('DecisionTree', DecisionTreeClassifier()),\n",
    "        ('RandomForest', RandomForestClassifier()),\n",
    "        ('AdaBoost', AdaBoostClassifier(base_estimator=LogisticRegression()))]\n",
    "\n",
    "    for name, clf in classifiers:\n",
    "        score = KFold_validation(clf, X, y)\n",
    "        row = [name]\n",
    "        row.extend(score)\n",
    "        scores.append(row)\n",
    "\n",
    "    df = pd.DataFrame(scores, columns = cols).T\n",
    "    df.columns = df.iloc[0]\n",
    "    df.drop(df.index[[0]], inplace = True)\n",
    "    df = df.apply(pd.to_numeric, errors = 'ignore')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metrics</th>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>LogisticReg</th>\n",
       "      <th>SGD</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>AdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.883330</td>\n",
       "      <td>0.882462</td>\n",
       "      <td>0.884524</td>\n",
       "      <td>0.877469</td>\n",
       "      <td>0.817344</td>\n",
       "      <td>0.802583</td>\n",
       "      <td>0.843716</td>\n",
       "      <td>0.826463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.884507</td>\n",
       "      <td>0.881430</td>\n",
       "      <td>0.887860</td>\n",
       "      <td>0.883472</td>\n",
       "      <td>0.809008</td>\n",
       "      <td>0.819548</td>\n",
       "      <td>0.869269</td>\n",
       "      <td>0.827792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.882010</td>\n",
       "      <td>0.883984</td>\n",
       "      <td>0.880231</td>\n",
       "      <td>0.869941</td>\n",
       "      <td>0.831042</td>\n",
       "      <td>0.776016</td>\n",
       "      <td>0.809178</td>\n",
       "      <td>0.842726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.883209</td>\n",
       "      <td>0.882670</td>\n",
       "      <td>0.884008</td>\n",
       "      <td>0.876548</td>\n",
       "      <td>0.819673</td>\n",
       "      <td>0.797150</td>\n",
       "      <td>0.838098</td>\n",
       "      <td>0.828838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metrics    LinearSVC  LogisticReg       SGD  MultinomialNB       KNN  \\\n",
       "accuracy    0.883330     0.882462  0.884524       0.877469  0.817344   \n",
       "precision   0.884507     0.881430  0.887860       0.883472  0.809008   \n",
       "recall      0.882010     0.883984  0.880231       0.869941  0.831042   \n",
       "f1_score    0.883209     0.882670  0.884008       0.876548  0.819673   \n",
       "\n",
       "metrics    DecisionTree  RandomForest  AdaBoost  \n",
       "accuracy       0.802583      0.843716  0.826463  \n",
       "precision      0.819548      0.869269  0.827792  \n",
       "recall         0.776016      0.809178  0.842726  \n",
       "f1_score       0.797150      0.838098  0.828838  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get model performances\n",
    "evaluate_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Bagging Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep frist 5 models with best performances\n",
    "# save the prediction in another file\n",
    "def predict_with_bagging():\n",
    "\n",
    "    # Loading training data\n",
    "    X, y = load_dataset_tokenized()\n",
    "    vectorizer = TfidfVectorizer(analyzer = 'word',\n",
    "                                 tokenizer = simple_return,\n",
    "                                 preprocessor = simple_return,\n",
    "                                 token_pattern = None)\n",
    "\n",
    "    X = vectorizer.fit_transform(X)\n",
    "\n",
    "    # Loading review file\n",
    "    df = pd.read_csv(comment_file)\n",
    "    df.dropna(inplace = True)\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    # Reformat the data\n",
    "    df['created_time'] = pd.to_datetime(df['created_time'], format = '%Y-%m-%d %H:%M:%S')\n",
    "    # Split the word in each review\n",
    "    df['title'].apply(lambda x: [w.strip() for w in x.split()])\n",
    "\n",
    "    texts = df['title']\n",
    "    texts = vectorizer.transform(texts)\n",
    "\n",
    "    # initialize the output\n",
    "    df['preds'] = 0\n",
    "\n",
    "    classifiers = [\n",
    "    ('LinearSVC', svm.LinearSVC()),\n",
    "    ('LogisticReg', LogisticRegression()),\n",
    "    ('SGD', SGDClassifier()),\n",
    "    ('MultinomialNB', naive_bayes.MultinomialNB()),\n",
    "    ('RandomForest', RandomForestClassifier())]\n",
    "    \n",
    "    for name, clf in classifiers:\n",
    "        clf.fit(X, y)\n",
    "        pred = clf.predict(texts)\n",
    "        df[name] = pred\n",
    "        df['preds'] = df['preds'] + df[name]\n",
    "    df['preds'] = df['preds'].apply(lambda x: 0 if x < 3 else 1)\n",
    "    \n",
    "    # generate the predcition\n",
    "    df.to_csv('generated_data/stock_comments_predicted.csv', index = False)\n",
    "    print(\"Prediction has saved to file\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction has saved to file\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_with_bagging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute BI-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bi(row):\n",
    "    \n",
    "    pos = row[row == 1].count()\n",
    "    neg = row[row == 0].count()\n",
    "    bi = np.log((1 + pos) / (1 + neg))\n",
    "\n",
    "    return bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group reviews by date\n",
    "grouped = prediction['preds'].groupby(prediction.created_time.dt.date)\n",
    "# Generate bi score of each day\n",
    "bi_index = grouped.apply(get_bi)\n",
    "bi_index = bi_index.rename(\"BI\")\n",
    "# Get trading date according to Shanghai Index file\n",
    "quotes = pd.read_csv('./data/sh000001.csv', parse_dates = ['date'])\n",
    "quotes.set_index('date', inplace = True)\n",
    "# Merge sentiment \n",
    "bi_index.index = pd.to_datetime(bi_index.index)\n",
    "merged = pd.merge(bi_index, quotes, how = 'left', left_index = True, right_index = True)\n",
    "merged.fillna(method = 'ffill', inplace = True)\n",
    "# Save the bi index\n",
    "merged.to_csv('generated_data/bi_idx.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
